{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression\n",
    "Regression models (both linear and non-linear) are used for predicting a real value, like salary for example. If your independent variable is time, then you are forecasting future values, otherwise your model is predicting present but unknown values. Regression technique vary from Linear Regression to SVR and Random Forests Regression.\n",
    "\n",
    "In this part, you will understand and learn how to implement the following Machine Learning Regression models:\n",
    "\n",
    "* Simple Linear Regression\n",
    "* Multiple Linear Regression\n",
    "* Polynomial Regression\n",
    "* Support Vector for Regression (SVR)\n",
    "* Decision Tree Classification\n",
    "* Random Forest Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing Template (from part 1):\n",
    "1. Get the dataset\n",
    "2. Importing the libraries\n",
    "3. Importing the Dataset\n",
    "4. ~~Dealing with Missing Data~~\n",
    "5. ~~Encoding Categorical Data~~\n",
    "6. Splitting the Dataset into the Training and Test sets\n",
    "7. Feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#Importing the libraries\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\nimport pandas as pd\\n\\n# Importing the dataset\\ndataset = pd.read_csv(\"Data.csv\")\\nX = dataset.iloc[:, :-1].values\\ny = datset.iloc[:, 3].values\\n\\n# Taking care of missing data\\nfrom sklearn.preprocessing import Imputer\\nimputer = Imputer(missing_values = \"NaN\", strategy = \"mean\", axis = 0)\\nimputer = imputer.fit(X[:, 1:3])\\nX[:, 1:3] = imputer.transform(X[:, 1:3])\\n\\n# Encoding categorical data\\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\\nlabelencoder_X = LabelEncoder()\\nX[:, 0] = labelencoder_X.fit_transform(X[:, 0])\\nonehotencoder = OneHotEncoder(categorical_features = [0])\\nX = onehotencoder.fit_transform(X).toarray()\\nlabelencoder_y = LabelEncoder()\\ny = labelencoder_y.fit_transform(y)\\n\\n# Splitting the dataset inot the Training and Test sets\\nfrom sklearn.model_selection import train_test_split\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\\n\\n# Feature scaling\\nfrom sklearn.preprocessing import StandardScaler\\nsc_X = StandardScaler()\\nX_train = sc_X.fit_transform(X_train)\\nX_test = sc_X.transform(X_test)'"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"#Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Importing the dataset\n",
    "dataset = pd.read_csv(\"Data.csv\")\n",
    "X = dataset.iloc[:, :-1].values\n",
    "y = datset.iloc[:, 3].values\n",
    "\n",
    "# Taking care of missing data\n",
    "from sklearn.preprocessing import Imputer\n",
    "imputer = Imputer(missing_values = \"NaN\", strategy = \"mean\", axis = 0)\n",
    "imputer = imputer.fit(X[:, 1:3])\n",
    "X[:, 1:3] = imputer.transform(X[:, 1:3])\n",
    "\n",
    "# Encoding categorical data\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "labelencoder_X = LabelEncoder()\n",
    "X[:, 0] = labelencoder_X.fit_transform(X[:, 0])\n",
    "onehotencoder = OneHotEncoder(categorical_features = [0])\n",
    "X = onehotencoder.fit_transform(X).toarray()\n",
    "labelencoder_y = LabelEncoder()\n",
    "y = labelencoder_y.fit_transform(y)\n",
    "\n",
    "# Splitting the dataset inot the Training and Test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "# Feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
